{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PM6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "October 17th, 2020<br>Hannah Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r publishersT\n",
    "%store -r allArticles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the format of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'link': 'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=100&oid=032&aid=0003030253',\n",
       " 'title': '하태경 “의사-간호사 이간질 택한 문 대통령”',\n",
       " 'datetime': datetime.datetime(2020, 9, 2, 17, 34),\n",
       " 'num_comments': 150,\n",
       " 'content': '하태경 국민의힘 의원이 지난달 26일 국회 회의를 주재하고 있다.   하태경 국민의힘(옛 미래통합당) 의원이 2일 문재인 대통령의 ‘간호사 격려’ 글에 “의사와 간호사 이간질시키는 문재인 대통령은 대통령이기를 포기하신 건가”라고 말했다  하 의원은 자신의 사회관계망서비스에서 이날 문 대통령의 메시지를 두고 “국민 이간질 해도해도 너무한다”면서 “의사와 간호사의 패싸움 하는 걸 조장하고 있다”고 말했다  그는 이어 “아무리 의사파업 중이라 해도 대통령이라면 절대 해서는 안될 행동”이라며 “해결책을 제시하지 못할망정 고생하는 간호사들을 부추겨 의사와 대결구도를 만들고 있으니 대통령이기를 포기하신 건지 되묻고 싶다”고 말했다  하 의원은 “문 대통령의 게시글을 본 국민 상당수가 두 눈을 의심할 정도”라며 “지금 대통령이 할 일은 더불어민주당이 약속한 의대증원 원점 재논의 명문화를 지시해 의사들을 즉각 병원에 복귀시키는 것”이라고 말했다  문 대통령은 이날 사회관계망서비스에 “전공의 등 의사들이 떠난 의료현장을 묵묵히 지키고 있는 간호사분들을 위로하며 헌신과 노고에 깊은 감사와 존경의 마음을 드린다”고 밝혔다  김은혜 국민의힘 대변인도 구두 논평을 통해 “(문 대통령의 메시지가) 의료진으로 표현되지만 대부분이 간호사였다. 대통령이 국민을 상대로 좌표를 찍었다”면서 “의사를 향한 대리전을 간호사들에 명하신 건가. 다음은 누구를 적으로 돌릴 셈인가”라고 말했다',\n",
       " 'reactions': {'good': 344, 'warm': 4, 'sad': 1, 'angry': 45, 'want': 3},\n",
       " 'recommends': 84,\n",
       " 'publisher': '경향신문'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allArticles[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a deep copy of allArticles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "allArticles_new = []\n",
    "for d in allArticles:\n",
    "    copy = {key: value for key, value in d.items()}\n",
    "    allArticles_new.append(copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Okt class in KoNLPy to split the content morphologically and attach them again with spaces in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "\n",
    "for a in allArticles_new:\n",
    "    content = ' '.join([x.strip() for x in a['content'].split()])\n",
    "    content = okt.morphs(content)\n",
    "    content = [x for x in content if x not in \"“”,\\\"()‘’·'…[]...-?\"]\n",
    "    a['content'] = ' '.join(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine data to see if there are more components to be cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_counter = Counter()\n",
    "for a in allArticles_new:\n",
    "    words = [x.strip() for x in a['content'].split()]\n",
    "    content_counter.update(words)\n",
    "content_counter.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling on Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list that only contains strings of article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all article content with new version\n",
    "allContent_new = [x['content'] for x in allArticles_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF vectorizer for content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF vectorizer\n",
    "tf_vectorizer_content = CountVectorizer(strip_accents = 'unicode',\n",
    "                                min_df = 0.05,\n",
    "                                max_df = 0.85,\n",
    "                                ngram_range = (2,5))\n",
    "\n",
    "dtm_tf_content = tf_vectorizer_content.fit_transform(allContent_new)\n",
    "print(dtm_tf_content.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_vectorizer_content.get_feature_names()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_vectorizer_content.get_feature_names()[dtm_tf_content.shape[1]//2:dtm_tf_content.shape[1]//2+50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_vectorizer_content.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF vectorizer for content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer\n",
    "tfidf_vectorizer_content = TfidfVectorizer(**tf_vectorizer_content.get_params())\n",
    "dtm_tfidf_content = tfidf_vectorizer_content.fit_transform(allContent_new)\n",
    "print(dtm_tfidf_content.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit both LDA models for content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA Models\n",
    "\n",
    "# TF DTM\n",
    "lda_tf_content = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "lda_tf_content.fit(dtm_tf_content)\n",
    "\n",
    "# TF-IDF DTM\n",
    "lda_tfidf_content = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "lda_tfidf_content.fit(dtm_tfidf_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Model\n",
    "pyLDAvis.sklearn.prepare(lda_tf_content, dtm_tf_content, tf_vectorizer_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Model\n",
    "pyLDAvis.sklearn.prepare(lda_tfidf_content, dtm_tfidf_content, tfidf_vectorizer_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling on Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list that only contains the refined titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTitles_new = []\n",
    "\n",
    "for a in allArticles_new:\n",
    "    title = ' '.join([x.strip() for x in a['title'].split()])\n",
    "    title = okt.morphs(title)\n",
    "    title = [x for x in title if x not in \"“”,\\\"()‘’·'…[]...-?\"]\n",
    "    allTitles_new.append(' '.join(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine data for further improvements in cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_counter = Counter()\n",
    "for t in allTitles_new:\n",
    "    words = [x.strip() for x in t.split()]\n",
    "    title_counter.update(words)\n",
    "title_counter.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make TF vectorizer for titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF vectorizer\n",
    "tf_vectorizer_title = CountVectorizer(strip_accents = 'unicode',\n",
    "                                min_df = 0.0015,\n",
    "                                max_df = 0.005,\n",
    "                                ngram_range = (2,5))\n",
    "\n",
    "dtm_tf_title = tf_vectorizer_title.fit_transform(allTitles_new)\n",
    "print(dtm_tf_title.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_vectorizer_title.get_feature_names()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_vectorizer_title.get_feature_names()[dtm_tf_title.shape[1]//2:dtm_tf_title.shape[1]//2+50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_vectorizer_title.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make TF-IDF vectorizer for titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer\n",
    "tfidf_vectorizer_title = TfidfVectorizer(**tf_vectorizer_title.get_params())\n",
    "dtm_tfidf_title = tfidf_vectorizer_title.fit_transform(allTitles_new)\n",
    "print(dtm_tfidf_title.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit both LDA models for article titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA Models\n",
    "\n",
    "# TF DTM\n",
    "lda_tf_title = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "lda_tf_title.fit(dtm_tf_title)\n",
    "\n",
    "# TF-IDF DTM\n",
    "lda_tfidf_title = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "lda_tfidf_title.fit(dtm_tfidf_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Model\n",
    "pyLDAvis.sklearn.prepare(lda_tf_title, dtm_tf_title, tf_vectorizer_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Model\n",
    "pyLDAvis.sklearn.prepare(lda_tfidf_title, dtm_tfidf_title, tfidf_vectorizer_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Topic Modeling Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary for translating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate = {\n",
    "    '경향신문': 'Kyunghyang Shinmun',\n",
    "    '국민일보': 'Kukmin Ilbo',\n",
    "    '동아일보': 'DongA Ilbo',\n",
    "    '문화일보': 'Munhwa Ilbo',\n",
    "    '서울신문': 'Seoul Shinmun',\n",
    "    '세계일보': 'Segye Ilbo',\n",
    "    '조선일보': 'Chosun Ilbo',\n",
    "    '중앙일보': 'JoongAng Ilbo',\n",
    "    '한겨레': 'Hangyoreh',\n",
    "    '한국일보': 'Hankuk Ilbo'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for getting lists of topic proportions for each publisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distrTopics(pList, publisher):\n",
    "    \"\"\"\n",
    "    pList is the list of probabilities for an LDA model.\n",
    "    publisher is the target publisher in which we are interested.\n",
    "    distrTopics() will return a list where each index corresponds to each topic\n",
    "    and each value is the number of articles for that topic.\n",
    "    This function is only valid for models with 5 topics.\n",
    "    The order of the items in pList must align with that of allArticles.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = [0, 0, 0, 0, 0]\n",
    "    for i in range(len(allArticles)):\n",
    "        aDict = allArticles[i]\n",
    "        if aDict['publisher'] == publisher:\n",
    "            # Get topic (index) with highest probability\n",
    "            maxP = 0\n",
    "            maxIndex = 0\n",
    "            for j in range(len(pList[i])):\n",
    "                maxP = max(maxP, pList[i][j])\n",
    "                if maxP == pList[i][j]:\n",
    "                    maxIndex = j\n",
    "            result[maxIndex] += 1\n",
    "    \n",
    "    total = sum(result)\n",
    "    result = [x/total for x in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_tfidf_content = lda_tfidf_content.transform(dtm_tfidf_content)\n",
    "probabilities_tf_content = lda_tf_content.transform(dtm_tf_content)\n",
    "probabilities_tfidf_title = lda_tfidf_title.transform(dtm_tfidf_title)\n",
    "probabilities_tf_title = lda_tf_title.transform(dtm_tf_title)\n",
    "\n",
    "topicDistr_tfidf_content = []\n",
    "topicDistr_tf_content = []\n",
    "topicDistr_tfidf_title = []\n",
    "topicDistr_tf_title = []\n",
    "\n",
    "\n",
    "for pbls in publishersT:\n",
    "    topicDistr_tfidf_content.append(distrTopics(probabilities_tfidf_content, pbls))\n",
    "    topicDistr_tf_content.append(distrTopics(probabilities_tf_content, pbls))\n",
    "    topicDistr_tfidf_title.append(distrTopics(probabilities_tfidf_title, pbls))\n",
    "    topicDistr_tf_title.append(distrTopics(probabilities_tf_title, pbls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for producing the barplots of topic proportions for each publisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barDistr(topicDistrList, xt, yt, unit, publisher, basis):\n",
    "    \"\"\"\n",
    "    topicDistrList is a list of proportions for each topic for each publisher.\n",
    "    xt is a list of ticks for the x axis.\n",
    "    yt is a list of ticks for the y axis.\n",
    "    unit is a string for display in the title and y axis.\n",
    "    publisher is the publisher in which we are interested.\n",
    "    basis is TF or TF-IDF, whichever the model was based on.\n",
    "    barDistr will display a plot of proportions of topics \n",
    "    for the articles by the publisher.\n",
    "    The publisher must be one that is in the list publishersT.\n",
    "    \"\"\"\n",
    "    \n",
    "    pIndex = publishersT.index(publisher)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot()\n",
    "    plt.bar(xt, topicDistrList[pIndex])\n",
    "    plt.title('Proportions of {} Topics for {} Based on {}'.format(unit, translate[publisher], basis))\n",
    "    plt.xlabel('Topics')\n",
    "    plt.ylabel('Number of {}s'.format(unit))\n",
    "    plt.xticks(xt)\n",
    "    plt.yticks(yt)\n",
    "    for i in range(5):\n",
    "        val = topicDistrList[pIndex][i]\n",
    "        plt.text(xt[i]-0.25, val+0.01, \"{}%\".format(round(val*100, 1)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in publishersT:\n",
    "    barDistr(topicDistr_tfidf_content, range(1,6), [0.1*x for x in range(0,11,2)], 'Content', p, 'TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in publishersT:\n",
    "    barDistr(topicDistr_tf_content, range(1,6), [0.1*x for x in range(0,11,2)], 'Content', p, 'TF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in publishersT:\n",
    "    barDistr(topicDistr_tfidf_title, range(1,6), [0.1*x for x in range(0,11,2)], 'Title', p, 'TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in publishersT:\n",
    "    barDistr(topicDistr_tf_title, range(1,6), [0.1*x for x in range(0,11,2)], 'Title', p, 'TF')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
